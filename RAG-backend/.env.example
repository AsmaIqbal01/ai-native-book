# Primary LLM Provider
# Options: xai, openai, gemini, openrouter
# Example configurations:

# Option 1: OpenRouter (Free tier available)
LLM_PROVIDER=openrouter
LLM_API_KEY=your_openrouter_api_key_here
LLM_BASE_URL=https://openrouter.ai/api/v1
LLM_MODEL=mistralai/devstral-2512:free

# Option 2: X.AI Grok
# LLM_PROVIDER=xai
# LLM_API_KEY=your_xai_api_key_here
# LLM_BASE_URL=https://api.x.ai/v1
# LLM_MODEL=grok-beta

# Fallback Provider 1 (OpenAI)
LLM_PROVIDER_FALLBACK_1=openai
LLM_API_KEY_FALLBACK_1=your_openai_api_key_here
LLM_BASE_URL_FALLBACK_1=https://api.openai.com/v1
LLM_MODEL_FALLBACK_1=gpt-4o-mini

# Fallback Provider 2 (Gemini)
LLM_PROVIDER_FALLBACK_2=gemini
LLM_API_KEY_FALLBACK_2=your_gemini_api_key_here
LLM_BASE_URL_FALLBACK_2=https://generativelanguage.googleapis.com/v1beta/openai/
LLM_MODEL_FALLBACK_2=gemini-2.0-flash-exp

# OpenAI (for embeddings if using OpenAI instead of Cohere)
OPENAI_API_KEY=your_openai_api_key_here

# Qdrant Vector Database
QDRANT_URL=https://your-cluster-id.qdrant.io
QDRANT_API_KEY=your_qdrant_api_key_here

# Neon Serverless Postgres
NEON_DATABASE_URL=postgresql://user:password@host/database?sslmode=require

# Application Configuration
APP_ENV=development
LOG_LEVEL=INFO

# CORS Configuration (comma-separated origins)
# For development, use "*" to allow all origins
# For production, specify exact origins
CORS_ORIGINS=*

# Optional: Cohere (for embeddings)
COHERE_API_KEY=your_cohere_api_key_here

# Optional: GitHub Token
GITHUB_TOKEN=your_github_token_here
